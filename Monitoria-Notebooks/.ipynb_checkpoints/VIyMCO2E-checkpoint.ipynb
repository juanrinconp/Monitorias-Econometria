{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49eb518",
   "metadata": {},
   "source": [
    "## Introducción a Python para el Análisis de datos\n",
    "### Variables instrumentales y MCO en dos etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d8b2bf",
   "metadata": {},
   "source": [
    "El punto del método de variables instrumentales es encontrar una variable que afecte a $X$ (nuestra variable con problemas de endogeneidad), pero que no afecte a $y$. El método mas usado en la practica es MCO en dos etapas (es importante resaltar que MCO en dos etapas también utiliza un instrumento para estimar el parámetro que se desea), ya que con este se puede estimar los modelos perfectamente identificados y los modelos sobre identificados. El método de variables instrumentales solo funciona en modelos perfectamente identificados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95f64a4",
   "metadata": {},
   "source": [
    "Una buena variable instrumental debe cumplir con dos condiciones:\n",
    "\n",
    "- Relevancia, es decir, que el instrumento este correlacionado con nuestra variable: $Cov(X,z) \\not= 0$. Si esto se cumple, veremos que también se va a cumplir que $E[X|z] \\not= 0$.\n",
    "    \n",
    "    \n",
    "    \n",
    "- Validez, es decir, que el instrumento  no este correlacionado con el error: $Cov(z,\\epsilon) = 0$. Si se cumple lo anterior, también se va a cumplir que $E[\\epsilon|z] = 0$.\n",
    "\n",
    "\n",
    "\n",
    "Es importante tener en cuenta que las estimaciones por VI o MCO en dos etapas siguen siendo sesgadas pero son consistentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019977e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "pathout = './data/'\n",
    "if not os.path.exists(pathout):\n",
    "    os.mkdir(pathout) \n",
    "pathgraphs = './graphs/'\n",
    "if not os.path.exists(pathgraphs): \n",
    "        os.mkdir(pathgraphs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b9a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias para MCO\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26f1963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libreria para MCO2E\n",
    "from linearmodels.iv import IV2SLS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab0f01",
   "metadata": {},
   "source": [
    "Para este ejemplo usaremos la base de datos CARD de Wooldridge, para determinar el efecto de la educación sobre el salario. Un problema común en este tipo de estimaciones es que posiblemente la habilidad de las personas sea una variable que afecte el salario, por lo que deberíamos incluirla pero no tenemos ninguna medida de habilidad. En este caso estamos frente a un problema de endogeneidad gracias a variables omitidas. Dado lo anterior optaremos por realizar la estimación usando el método de VI. Este método nos dará estimaciones sesgadas, igual que MCO pero consistentes. Para usar este método en Python haremos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9662d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nearc2</th>\n",
       "      <th>nearc4</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>fatheduc</th>\n",
       "      <th>motheduc</th>\n",
       "      <th>weight</th>\n",
       "      <th>momdad14</th>\n",
       "      <th>sinmom14</th>\n",
       "      <th>...</th>\n",
       "      <th>smsa66</th>\n",
       "      <th>wage</th>\n",
       "      <th>enroll</th>\n",
       "      <th>KWW</th>\n",
       "      <th>IQ</th>\n",
       "      <th>married</th>\n",
       "      <th>libcrd14</th>\n",
       "      <th>exper</th>\n",
       "      <th>lwage</th>\n",
       "      <th>expersq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158413.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>6.306275</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>380166.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.175867</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>367470.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>721</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>6.580639</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>380166.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5.521461</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>367470.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>6.591674</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>5218</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>82135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.814130</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>5219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88765.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>6.175867</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>5220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89271.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.214608</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008</th>\n",
       "      <td>5221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110376.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.569481</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>5225</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81081.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>525</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6.263398</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3010 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  nearc2  nearc4  educ  age  fatheduc  motheduc    weight  momdad14  \\\n",
       "0        2       0       0     7   29       NaN       NaN  158413.0         1   \n",
       "1        3       0       0    12   27       8.0       8.0  380166.0         1   \n",
       "2        4       0       0    12   34      14.0      12.0  367470.0         1   \n",
       "3        5       1       1    11   27      11.0      12.0  380166.0         1   \n",
       "4        6       1       1    12   34       8.0       7.0  367470.0         1   \n",
       "...    ...     ...     ...   ...  ...       ...       ...       ...       ...   \n",
       "3005  5218       0       1    12   25       8.0      12.0   82135.0         1   \n",
       "3006  5219       0       1    13   34       NaN       NaN   88765.0         1   \n",
       "3007  5220       0       1    12   24      11.0       NaN   89271.0         0   \n",
       "3008  5221       0       1    12   31       NaN       NaN  110376.0         1   \n",
       "3009  5225       0       1    13   26       NaN       NaN   81081.0         0   \n",
       "\n",
       "      sinmom14  ...  smsa66  wage  enroll   KWW     IQ  married  libcrd14  \\\n",
       "0            0  ...       1   548       0  15.0    NaN      1.0       0.0   \n",
       "1            0  ...       1   481       0  35.0   93.0      1.0       1.0   \n",
       "2            0  ...       1   721       0  42.0  103.0      1.0       1.0   \n",
       "3            0  ...       1   250       0  25.0   88.0      1.0       1.0   \n",
       "4            0  ...       1   729       0  34.0  108.0      1.0       0.0   \n",
       "...        ...  ...     ...   ...     ...   ...    ...      ...       ...   \n",
       "3005         0  ...       0   335       0  15.0    NaN      1.0       0.0   \n",
       "3006         0  ...       0   481       0  43.0    NaN      1.0       1.0   \n",
       "3007         0  ...       0   500       0  25.0  109.0      1.0       0.0   \n",
       "3008         0  ...       0   713       0  32.0  107.0      1.0       1.0   \n",
       "3009         0  ...       0   525       1  27.0    NaN      1.0       0.0   \n",
       "\n",
       "      exper     lwage  expersq  \n",
       "0        16  6.306275      256  \n",
       "1         9  6.175867       81  \n",
       "2        16  6.580639      256  \n",
       "3        10  5.521461      100  \n",
       "4        16  6.591674      256  \n",
       "...     ...       ...      ...  \n",
       "3005      7  5.814130       49  \n",
       "3006     15  6.175867      225  \n",
       "3007      6  6.214608       36  \n",
       "3008     13  6.569481      169  \n",
       "3009      7  6.263398       49  \n",
       "\n",
       "[3010 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_stata(pathout + 'CARD.dta')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a6ddfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'nearc2', 'nearc4', 'educ', 'age', 'fatheduc', 'motheduc',\n",
       "       'weight', 'momdad14', 'sinmom14', 'step14', 'reg661', 'reg662',\n",
       "       'reg663', 'reg664', 'reg665', 'reg666', 'reg667', 'reg668', 'reg669',\n",
       "       'south66', 'black', 'smsa', 'south', 'smsa66', 'wage', 'enroll', 'KWW',\n",
       "       'IQ', 'married', 'libcrd14', 'exper', 'lwage', 'expersq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b898c2e8",
   "metadata": {},
   "source": [
    "En este caso utilizaremos la variable nearc4 como instrumento de educ. Esta variable nos indica si las personas viven cerca a una universidad. Intuitivamente esta variable puede servir como instrumento ya que esto puede afectar los años de la educación (dado que si están cerca a una universidad los costos de transporte son menores y esto los incentivaría a estudiar mas) pero difícilmente afecte el salario de las personas.\n",
    "   \n",
    "Para esto, primero debemos ver si se cumple cumple con relevancia, y este instrumento Z esta correlacionado con nuestra variable X. Esto lo haremos realizando la regresión de nearc4 en educ y agregando controles. Lo ideal es que el efecto parcial de nearc4 sobre educ sea estadísticamente significativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d2e5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   educ   R-squared:                       0.474\n",
      "Model:                            OLS   Adj. R-squared:                  0.473\n",
      "Method:                 Least Squares   F-statistic:                     451.9\n",
      "Date:                Mon, 24 May 2021   Prob (F-statistic):               0.00\n",
      "Time:                        20:13:02   Log-Likelihood:                -6266.1\n",
      "No. Observations:                3010   AIC:                         1.255e+04\n",
      "Df Residuals:                    3003   BIC:                         1.259e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         16.6592      0.176     94.446      0.000      16.313      17.005\n",
      "nearc4         0.3373      0.083      4.089      0.000       0.176       0.499\n",
      "exper         -0.4100      0.034    -12.169      0.000      -0.476      -0.344\n",
      "expersq        0.0007      0.002      0.444      0.657      -0.003       0.004\n",
      "black         -1.0061      0.090    -11.224      0.000      -1.182      -0.830\n",
      "smsa           0.4039      0.085      4.758      0.000       0.237       0.570\n",
      "south         -0.2915      0.079     -3.679      0.000      -0.447      -0.136\n",
      "==============================================================================\n",
      "Omnibus:                       14.376   Durbin-Watson:                   1.761\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               14.555\n",
      "Skew:                           0.169   Prob(JB):                     0.000691\n",
      "Kurtosis:                       2.955   Cond. No.                         661.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X0 = df[['nearc4', 'exper' , 'expersq' , 'black' , 'smsa' , 'south']] \n",
    "X0 = sm.add_constant(X0)\n",
    "Y0 = df.educ\n",
    "reg0 = sm.OLS(endog=Y0, exog=X0, missing = 'drop',)\n",
    "reg0 = reg0.fit()\n",
    "print(reg0.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172eefb1",
   "metadata": {},
   "source": [
    "Como podemos ver, el coeficiente de nearc4 es positivo y altamente significativo, por lo que cumple con relevancia.\n",
    "Para que se cumpla con validez se debe asegurar de incluir todas las variables relevantes (menos habilidad, la cual no tenemos) y argumentar el porque nuestra variable instrumental no esta correlacionada con el termino del error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e76680",
   "metadata": {},
   "source": [
    "Ahora realicemos la regresión por MCO de la educación en el logaritmo del salario, para mas adelante realizar al regresión por MC2E y poder comparar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f5f3a",
   "metadata": {},
   "source": [
    "#### Regresión de educ en lwage (mas controles) por MCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16dd14f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.291\n",
      "Model:                            OLS   Adj. R-squared:                  0.289\n",
      "Method:                 Least Squares   F-statistic:                     204.9\n",
      "Date:                Mon, 24 May 2021   Prob (F-statistic):          1.52e-219\n",
      "Time:                        20:13:03   Log-Likelihood:                -1308.7\n",
      "No. Observations:                3010   AIC:                             2631.\n",
      "Df Residuals:                    3003   BIC:                             2673.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.7337      0.068     70.022      0.000       4.601       4.866\n",
      "educ           0.0740      0.004     21.113      0.000       0.067       0.081\n",
      "exper          0.0836      0.007     12.575      0.000       0.071       0.097\n",
      "expersq       -0.0022      0.000     -7.050      0.000      -0.003      -0.002\n",
      "black         -0.1896      0.018    -10.758      0.000      -0.224      -0.155\n",
      "smsa           0.1614      0.016     10.365      0.000       0.131       0.192\n",
      "south         -0.1249      0.015     -8.259      0.000      -0.155      -0.095\n",
      "==============================================================================\n",
      "Omnibus:                       58.553   Durbin-Watson:                   1.861\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               69.495\n",
      "Skew:                          -0.280   Prob(JB):                     8.12e-16\n",
      "Kurtosis:                       3.491   Cond. No.                     1.28e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.28e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X1 = df[['educ', 'exper' , 'expersq' , 'black' , 'smsa' , 'south']] \n",
    "X1 = sm.add_constant(X1)\n",
    "Y1 = df.lwage\n",
    "reg1 = sm.OLS(endog=Y1, exog=X1, missing = 'drop',)\n",
    "reg1 = reg1.fit()\n",
    "print(reg1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d6cdf5",
   "metadata": {},
   "source": [
    "#### Regresión de educ en lwage (mas controles) por MC2E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941f3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'lwage ~ 1 + exper + expersq  + black + smsa + south + [educ ~ nearc4]'\n",
    "regVI = IV2SLS.from_formula(formula, df)\n",
    "regVI = regVI.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d36fb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                      0.2252\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.2237\n",
      "No. Observations:                3010   F-statistic:                    792.07\n",
      "Date:                Mon, May 24 2021   P-value (F-stat)                0.0000\n",
      "Time:                        20:13:03   Distribution:                  chi2(6)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.7528     0.8167     4.5948     0.0000      2.1520      5.3536\n",
      "exper          0.1075     0.0211     5.0916     0.0000      0.0661      0.1489\n",
      "expersq       -0.0023     0.0003    -6.5949     0.0000     -0.0030     -0.0016\n",
      "black         -0.1308     0.0515    -2.5422     0.0110     -0.2316     -0.0300\n",
      "smsa           0.1313     0.0298     4.4115     0.0000      0.0730      0.1897\n",
      "south         -0.1049     0.0229    -4.5809     0.0000     -0.1498     -0.0600\n",
      "educ           0.1323     0.0485     2.7264     0.0064      0.0372      0.2274\n",
      "==============================================================================\n",
      "\n",
      "Endogenous: educ\n",
      "Instruments: nearc4\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "print(regVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d62537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para exportar las tablas en latex\n",
    "from pystout import pystout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b8cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pystout(models=[reg1, regVI],\n",
    "        file='VI.tex',\n",
    "        addnotes=['*$p < 0.1$ , ** $p < 0.05$ , *** $p < 0.01$',\n",
    "                  'Standar errors in parentheses.'],\n",
    "        digits=3,\n",
    "        endog_names=['MCO','MC2E'],\n",
    "        varlabels={'const':'Constant','displacement':'Disp','mpg':'MPG'},\n",
    "        mgroups={'(1)':[1,1],'(2)':[2,2]},\n",
    "        modstat={'nobs':'Obs','rsquared':'R\\sym{2}','fvalue':'F-stat'},\n",
    "        stars={.1:'*',.05:'**',.01:'***'}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90fcaa0",
   "metadata": {},
   "source": [
    "![title](graphs/VI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f62bd7",
   "metadata": {},
   "source": [
    "Como podemos ver, efectivamente teníamos problemas de endogeneidad. Al usar el método de MC2E el coeficiente de educ aumento en magnitud. Ahora, diremos que:\n",
    "\n",
    "#### Ante un aumento de un año en la educación de las personas, el salario aumentara en promedio en 13.2%, siendo esta una estimación significativa al 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c385d95",
   "metadata": {},
   "source": [
    "Este es el final del quinto documento de Introducción a Python para el análisis de datos. Si necesitan cualquier cosa pueden ponerse en contacto conmigo al correo Juan.rinconp@javeriana.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd051a87",
   "metadata": {},
   "source": [
    "Bibliografía:\n",
    "\n",
    "- Wooldridge, Jeffrey M. (2018), Introductory Econometrics: A Modern Approach, Sixth Edition, Cengage Learning.\n",
    "\n",
    "- Garlati, A. [Pablo Adrian Garlati]. (2020, Diciembre). Variables Instrumentales y Mínimos Cuadrados en dos Etapas [Archivo de video]. Disponible en: https://www.youtube.com/watch?v=1jYhcUvWv4g&t=4638s\n",
    "\n",
    "- linearmodels. (2017) , Estimation Methods - IV2SLS. disponible en: https://bashtage.github.io/linearmodels/doc/iv/methods.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
